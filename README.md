
# Kobe Bryant Shot Prediction - Framework TDSP

## Projeto de Engenharia de Machine Learning - Previs√£o de Acertos do Kobe Bryant

### Objetivo

Desenvolver um preditor de arremessos de Kobe Bryant usando duas abordagens: Regress√£o e Classifica√ß√£o. O projeto deve prever se Kobe Bryant acertou ou errou um arremesso, utilizando o Framework TDSP (Team Data Science Process).

---

## Como executar o projeto

### Criar ambiente Conda e instalar depend√™ncias:
Com YAML 
```bash
conda env create -f environment.yml
```

### Executar o pipeline completo do plrojeto:
```bash
python code/pipeline.py
```

### Exibir o dashboard:
```bash
streamlit run outuputs/dashboards/streamlit_app.py
```

### Abrir o MLflow:
```bash
mlflow ui
```
Acessar: [http://localhost:5000](http://localhost:5000)


## Principais tecnologias utilizadas no projeto 
- Python 3.10
- Pycaret 3.0.0
- Seaborn 0.13.2
- Pandas 2.2.3
- Scikit-Learn 1.5.1
- MLflow 2.21.2
- Streamlit 1.43.2
- NumPy 2.1.3
- Matplotlib 3.9.2

## M√©tricas Finais (Produ√ß√£o)

| **M√©trica**           | **Valor**               |
|-----------------------|------------------------|
| Modelo Escolhido      | √Årvore de Decis√£o       |
| Log Loss (Produ√ß√£o)   | 0.5698                  |
| F1-Score (Produ√ß√£o)   | 0.5324                  |

O modelo de **√Årvore de Decis√£o** foi selecionado para produ√ß√£o por apresentar melhor desempenho geral em m√©tricas cr√≠ticas como `F1-Score` e `Log Loss` em compara√ß√£o √† Regress√£o Log√≠stica. Al√©m disso, a **√Årvore de Decis√£o** oferece maior interpretabilidade e melhor desempenho na base de produ√ß√£o.  

Embora o `Log Loss` n√£o seja perfeito, o modelo apresentou um desempenho consistente em dados fora da amostra, sugerindo que est√° bem ajustado para o problema.


## Estrutura do Projeto

O projeto segue a estrutura proposta pelo TDSP:

```
üìÅ kobe_shot_prediction_tdsp/
‚îú‚îÄ‚îÄ code/
‚îÇ   ‚îú‚îÄ‚îÄ preparacao_dados.py
‚îÇ   ‚îú‚îÄ‚îÄ treinamento.py
‚îÇ   ‚îú‚îÄ‚îÄ aplicacao.py
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dataset_kobe_dev.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dataset_kobe_prod.parquet
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ       ‚îú‚îÄ‚îÄ data_filtered.parquet
‚îÇ       ‚îú‚îÄ‚îÄ base_train.parquet
‚îÇ       ‚îî‚îÄ‚îÄ base_test.parquet
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ diagramas/
‚îÇ   ‚îú‚îÄ‚îÄ relatorios/
‚îú‚îÄ‚îÄ outputs/
‚îÇ   ‚îî‚îÄ‚îÄ dashboards/
‚îÇ       ‚îî‚îÄ‚îÄ streamlit_app.py
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ environment.yml
```

---

# **Respostas**

### Quest√£o 1) A solu√ß√£o criada nesse projeto deve ser disponibilizada em reposit√≥rio git e disponibilizada em servidor de reposit√≥rios (Github (recomendado), Bitbucket ou Gitlab). O projeto deve obedecer o Framework TDSP da Microsoft (estrutura de arquivos, arquivo requirements.txt e arquivo README - com as respostas pedidas nesse projeto, al√©m de outras informa√ß√µes pertinentes). Todos os artefatos produzidos dever√£o conter informa√ß√µes referentes a esse projeto (n√£o ser√£o aceitos documentos vazios ou fora de contexto). Escreva o link para seu reposit√≥rio.
### Resposta: https://github.com/marcelobazevedo/kobe_shot_prediction_tdsp
---
### Quest√£o 2) Iremos desenvolver um preditor de arremessos usando duas abordagens (regress√£o e classifica√ß√£o) para prever se o "Black Mamba" (apelido de Kobe) acertou ou errou a cesta. Baixe os dados de desenvolvimento e produ√ß√£o aqui (datasets: dataset_kobe_dev.parquet e dataset_kobe_prod.parquet). Salve-os numa pasta /data/raw na raiz do seu reposit√≥rio. Para come√ßar o desenvolvimento, desenhe um diagrama que demonstra todas as etapas necess√°rias para esse projeto, desde a aquisi√ß√£o de dados, passando pela cria√ß√£o dos modelos, indo at√© a opera√ß√£o do modelo.
### Resposta: 

1. **Aquisi√ß√£o de Dados**
   - Coleta dos arquivos e armazenamento na pasta `data/raw`.

2. **Pr√©-processamento**
   - Remo√ß√£o de nulos, sele√ß√£o de colunas relevantes e salvamento em `data/processed`.

3. **Separa√ß√£o Treino/Teste**
   - Divis√£o estratificada 80/20 dos dados e armazenamento em `base_train.parquet` e `base_test.parquet`.

4. **Treinamento**
   - Aplica√ß√£o de modelos de Regress√£o Log√≠stica e √Årvore de Decis√£o utilizando PyCaret e MLFlow.

5. **Avalia√ß√£o**
   - M√©tricas calculadas: Log-Loss, F1-score, entre outras.
   - Sele√ß√£o do melhor modelo baseado nas m√©tricas calculadas.

6. **Deploy/Operacionaliza√ß√£o**
   - Deploy do modelo utilizando MLFlow, API Flask ou Streamlit.

7. **Monitoramento**
   - Monitoramento cont√≠nuo das m√©tricas de desempenho em produ√ß√£o.

8. **Atualiza√ß√£o do Modelo**
   - Reavalia√ß√£o e ajuste do modelo com novas coletas de dados.

### Diagrama das etapas necess√°ria para o projeto

![Diagrama do Pipeline](./docs/diagramas/questao_2_fluxograma.png)

---
### Quest√£o 3) Como as ferramentas Streamlit, MLFlow, PyCaret e Scikit-Learn auxiliam na constru√ß√£o dos pipelines descritos anteriormente? A resposta deve abranger os seguintes aspectos:

#### - Rastreamento de experimentos;
#### - Fun√ß√µes de treinamento;
#### - Monitoramento da sa√∫de do modelo;
#### - Atualiza√ß√£o de modelo;
#### - Provisionamento (Deployment).
### Resposta: 

####  PyCaret
- Facilita o treinamento e a compara√ß√£o de modelos atrav√©s de fun√ß√µes simplificadas.
- Permite testar m√∫ltiplos algoritmos de classifica√ß√£o e regress√£o.

####  Scikit-Learn
- Fornece algoritmos de machine learning essenciais para o projeto.
- √â utilizado em conjunto com o PyCaret para o treinamento dos modelos.

####  MLFlow
- Usado para rastrear experimentos e registrar m√©tricas.
- Facilita o deploy do modelo final.
- Permite monitorar o desempenho do modelo.

####  Streamlit
- Permite a cria√ß√£o de dashboards interativos para visualiza√ß√£o dos resultados.
- Facilita o monitoramento do desempenho do modelo.

---

### Quest√£o 4) Com base no diagrama realizado na quest√£o 2, aponte os artefatos que ser√£o criados ao longo de um projeto. Para cada artefato, a descri√ß√£o detalhada de sua composi√ß√£o.
### Resposta: 

- `data_filtered.parquet`: Conjunto de dados limpo e filtrado.
- `base_train.parquet`: Dados de treino (80%).
- `base_test.parquet`: Dados de teste (20%).
- `final_model.pkl`: Modelo treinado e registrado no MLFlow.
- **Dashboard Streamlit**: Visualiza√ß√£o dos resultados.

---


### Quest√£o 5) Implemente o pipeline de processamento de dados com o mlflow, rodada (run) com o nome `"PreparacaoDados"`:

- **a.** Os dados devem estar localizados em:
  - `/data/raw/dataset_kobe_dev.parquet` 
  - `/data/raw/dataset_kobe_prod.parquet` 

- **b.** Observe que h√° dados faltantes na base de dados! As linhas que possuem dados faltantes devem ser desconsideradas. Para esse exerc√≠cio ser√£o apenas consideradas as colunas: 
  - `lat`
  - `lon`
  - `minutes_remaining`
  - `period`
  - `playoffs`
  - `shot_distance`
  - `shot_made_flag` (vari√°vel alvo onde: `0` = erro, `1` = acerto)
  
  O dataset resultante ser√° armazenado na pasta:  
  `/data/processed/data_filtered.parquet`  

  Ainda sobre essa sele√ß√£o, qual a dimens√£o resultante do dataset?

- **c.** Separe os dados em treino (80%) e teste (20%) usando uma escolha aleat√≥ria e estratificada. 

  - Armazene os datasets resultantes em:  
    - `/data/processed/base_train.parquet`
    - `/data/processed/base_test.parquet`
    
  Explique como a escolha de treino e teste afetam o resultado do modelo final. Quais estrat√©gias ajudam a minimizar os efeitos de vi√©s de dados?

- **d.** Registre os par√¢metros (% teste) e m√©tricas (tamanho de cada base) no MLFlow.


### Resposta: 

A pipeline de processamento de dados inclui as seguintes etapas:
- Carregamento e limpeza dos dados.
- Sele√ß√£o das colunas especificadas (`lat`, `lon`, `minutes_remaining`, `period`, `playoffs`, `shot_distance`, `shot_made_flag`).
- Remo√ß√£o de linhas com valores ausentes.
- Separa√ß√£o dos dados em treino e teste (80% e 20%).
- Registro de m√©tricas no MLFlow.

---
### Quest√£o 6) Implementar o pipeline de treinamento do modelo com o MlFlow usando o nome "Treinamento" 
- **a.** Com os dados separados para treinamento, treine um modelo com regress√£o log√≠stica do sklearn usando a biblioteca pyCaret.
- **b.** Registre a fun√ß√£o custo "log loss" usando a base de teste
- **c.** Com os dados separados para treinamento, treine um modelo de √°rvore de decis√£o do sklearn usando a biblioteca pyCaret.
- **d.** Registre a fun√ß√£o custo "log loss" e F1_score para o modelo de √°rvore.
- **e.** Selecione um dos dois modelos para finaliza√ß√£o e justifique sua escolha.

### Resposta: 
## 6. Pipeline de Treinamento do Modelo com o MLFlow (`Treinamento`)

Implementar o pipeline de treinamento do modelo com o MLFlow usando o nome `"Treinamento"`.

### a. Treinamento do Modelo de Regress√£o Log√≠stica

- Com os dados separados para treinamento, um modelo de **Regress√£o Log√≠stica** √© treinado utilizando a biblioteca **PyCaret**.
- O PyCaret facilita o processo de configura√ß√£o, treinamento, compara√ß√£o de modelos e registro autom√°tico no MLFlow.

### b. Registro da Fun√ß√£o Custo - `Log Loss` (Regress√£o Log√≠stica)

- A m√©trica **Log Loss** √© calculada utilizando a base de teste (`base_test.parquet`).
- O resultado √© registrado no MLFlow para posterior compara√ß√£o com outros modelos.

### c. Treinamento do Modelo de √Årvore de Decis√£o

- Com os dados separados para treinamento, um modelo de **√Årvore de Decis√£o** √© treinado utilizando a biblioteca **PyCaret**.
- Assim como na Regress√£o Log√≠stica, o PyCaret √© utilizado para automatizar o processo de treinamento e registro de m√©tricas no MLFlow.

### d. Registro das M√©tricas - `Log Loss` e `F1 Score` (√Årvore de Decis√£o)

- As m√©tricas **Log Loss** e **F1 Score** s√£o calculadas utilizando a base de teste (`base_test.parquet`).
- Ambas s√£o registradas no MLFlow, permitindo a compara√ß√£o direta entre os modelos treinados.

### e. Sele√ß√£o do Modelo Final

- O modelo selecionado para finaliza√ß√£o foi a **√Årvore de Decis√£o**, com base na compara√ß√£o das m√©tricas `Log Loss` e `F1 Score`.
- A **√Årvore de Decis√£o** foi escolhida devido ao seu melhor desempenho em rela√ß√£o ao `F1 Score`, o que indica melhor equil√≠brio entre precis√£o e revoca√ß√£o.
- Al√©m disso, a √°rvore de decis√£o oferece maior interpretabilidade, facilitando a an√°lise dos resultados.

> **Justificativa:** Embora o modelo de Regress√£o Log√≠stica apresente um desempenho satisfat√≥rio, a **√Årvore de Decis√£o** obteve um melhor `F1 Score`, o que √© relevante considerando a necessidade de precis√£o e revoca√ß√£o balanceadas no problema proposto.
---
### Quest√£o 7) Registre o modelo de classifica√ß√£o e o sirva atrav√©s do MLFlow (ou como uma API local, ou embarcando o modelo na aplica√ß√£o). Desenvolva um pipeline de aplica√ß√£o (aplicacao.py) para carregar a base de produ√ß√£o (/data/raw/dataset_kobe_prod.parquet) e aplicar o modelo. Nomeie a rodada (run) do mlflow como ‚ÄúPipelineAplicacao‚Äù e publique, tanto uma tabela com os resultados obtidos (artefato como .parquet), quanto log as m√©tricas do novo log loss e f1_score do modelo.
- **a.** O modelo √© aderente a essa nova base? O que mudou entre uma base e outra? Justifique.
- **b.** Descreva como podemos monitorar a sa√∫de do modelo no cen√°rio com e sem a disponibilidade da vari√°vel resposta para o modelo em opera√ß√£o.
- **c.** Descreva as estrat√©gias reativa e preditiva de retreinamento para o modelo em opera√ß√£o.

### Resposta: 

## 7. Registro e Servir do Modelo com o MLFlow (`PipelineAplicacao`)

Implementar o pipeline de aplica√ß√£o do modelo treinado, servir o modelo e registrar os resultados utilizando o **MLFlow** com o nome `"PipelineAplicacao"`.

---

### a. O modelo √© aderente a essa nova base? O que mudou entre uma base e outra? Justifique.

- **Ader√™ncia do Modelo:** Ap√≥s aplicar o modelo treinado na base de produ√ß√£o (`/data/raw/dataset_kobe_prod.parquet`), as m√©tricas registradas (`Log Loss` e `F1 Score`) devem ser comparadas com aquelas obtidas durante o treinamento e teste iniciais.
- **Mudan√ßas entre as bases:**
  - A base de produ√ß√£o pode apresentar distribui√ß√µes diferentes nas vari√°veis de entrada (`lat`, `lng`, `minutes_remaining`, `period`, `playoffs`, `shot_distance`) em rela√ß√£o aos dados usados para o treinamento e teste (`dataset_kobe_dev.parquet`).
  - Caso as m√©tricas calculadas na base de produ√ß√£o sejam significativamente piores do que aquelas obtidas durante o treinamento, √© poss√≠vel que o modelo n√£o seja adequado para a nova base de produ√ß√£o.
- **Justificativa:** 
  - O modelo √© considerado aderente se suas m√©tricas mantiverem um desempenho consistente quando aplicado √† nova base.
  - Desvios significativos indicam que o modelo deve ser reavaliado ou retreinado para melhor se adequar √†s caracter√≠sticas da base de produ√ß√£o.

---

### b. Descreva como podemos monitorar a sa√∫de do modelo no cen√°rio com e sem a disponibilidade da vari√°vel resposta para o modelo em opera√ß√£o.

1. **Cen√°rio com a disponibilidade da vari√°vel resposta (`shot_made_flag`):**
   - Quando a vari√°vel resposta (`shot_made_flag`) est√° dispon√≠vel, √© poss√≠vel monitorar o desempenho do modelo de maneira cont√≠nua.
   - M√©tricas como `Log Loss`, `F1 Score`, `Accuracy`, entre outras, podem ser calculadas e comparadas com os valores obtidos durante o treinamento inicial.
   - Essas m√©tricas devem ser registradas no MLFlow regularmente para facilitar o monitoramento e an√°lise da sa√∫de do modelo.

2. **Cen√°rio sem a disponibilidade da vari√°vel resposta (Produ√ß√£o sem labels):**
   - Sem a vari√°vel resposta (`shot_made_flag`), o monitoramento deve ser feito de forma indireta.
   - Poss√≠veis abordagens incluem:
     - **Monitoramento de Distribui√ß√£o:** Comparar a distribui√ß√£o das previs√µes atuais com as distribui√ß√µes obtidas durante o treinamento.
     - **Monitoramento da Confian√ßa:** Acompanhar os `Confidence Scores` das previs√µes para identificar padr√µes an√¥malos.
     - **Detec√ß√£o de Drift:** Detectar mudan√ßas nas distribui√ß√µes dos dados de entrada que possam indicar degrada√ß√£o do desempenho do modelo.
   - Este monitoramento pode ser registrado no MLFlow por meio de m√©tricas customizadas ou artefatos gerados periodicamente.

---

### c. Descreva as estrat√©gias reativa e preditiva de retreinamento para o modelo em opera√ß√£o.

1. **Estrat√©gia Reativa:**
   - O retreinamento √© realizado **ap√≥s** a detec√ß√£o de uma queda significativa no desempenho do modelo.
   - A degrada√ß√£o √© identificada por meio de monitoramento cont√≠nuo das m√©tricas (`Log Loss`, `F1 Score`) registradas no MLFlow.
   - Quando uma m√©trica cai abaixo de um limite pr√©-definido, o retreinamento √© acionado.
   - Exemplo: Se o `F1 Score` cair abaixo de 0.50, o modelo √© retreinado usando uma nova amostra de dados atualizados.

2. **Estrat√©gia Preditiva:**
   - O retreinamento √© realizado de maneira **preventiva**, antes que o desempenho do modelo se deteriore.
   - T√©cnicas de previs√£o s√£o aplicadas para identificar quando o modelo precisa ser atualizado.
   - Pode envolver o uso de algoritmos de detec√ß√£o de drift ou monitoramento cont√≠nuo das distribui√ß√µes dos dados de entrada.
   - Este m√©todo √© √∫til para evitar quedas bruscas de desempenho, mantendo o modelo sempre atualizado.

---

### Quest√£o 8) Implemente um dashboard de monitoramento da opera√ß√£o usando Streamlit.

Um dashboard interativo foi implementado usando Streamlit para monitorar o desempenho do modelo.

```bash
streamlit run outputs/dashboards/streamlit_app.py
```
![Dashboard Streamlit](./docs/imagens/dashboard_streamlit.png)
---
