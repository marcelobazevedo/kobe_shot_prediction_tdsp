
# Kobe Bryant Shot Prediction - Framework TDSP

## Projeto de Engenharia de Machine Learning - PrevisÃ£o de Acertos do Kobe Bryant

### Objetivo

Desenvolver um preditor de arremessos de Kobe Bryant usando duas abordagens: RegressÃ£o e ClassificaÃ§Ã£o. O projeto deve prever se Kobe Bryant acertou ou errou um arremesso, utilizando o Framework TDSP (Team Data Science Process).

---

## Como executar o projeto

### Criar ambiente Conda e instalar dependÃªncias:
Com YAML 
```bash
conda env create -f environment.yml
```

### Executar o pipeline completo do plrojeto:
```bash
python code/pipeline.py
```

### Exibir o dashboard:
```bash
streamlit run outuputs/dashboards/streamlit_app.py
```

### Abrir o MLflow:
```bash
mlflow ui
```
Acessar: [http://localhost:5000](http://localhost:5000)


## Principais tecnologias utilizadas no projeto 
- Python 3.10
- Pycaret 3.0.0
- Seaborn 0.13.2
- Pandas 2.2.3
- Scikit-Learn 1.5.1
- MLflow 2.21.2
- Streamlit 1.43.2
- NumPy 2.1.3
- Matplotlib 3.9.2

## MÃ©tricas Finais (ProduÃ§Ã£o)

| **MÃ©trica**           | **Valor**               |
|-----------------------|------------------------|
| Modelo Escolhido      | Ãrvore de DecisÃ£o       |
| Log Loss (ProduÃ§Ã£o)   | 0.5698                  |
| F1-Score (ProduÃ§Ã£o)   | 0.5324                  |

> O modelo de **Ãrvore de DecisÃ£o** foi selecionado para produÃ§Ã£o por apresentar melhor desempenho geral em mÃ©tricas crÃ­ticas como `F1-Score` e `Log Loss` em comparaÃ§Ã£o Ã  RegressÃ£o LogÃ­stica. AlÃ©m disso, a **Ãrvore de DecisÃ£o** oferece maior interpretabilidade e melhor desempenho na base de produÃ§Ã£o.  
>
> Embora o `Log Loss` nÃ£o seja perfeito, o modelo apresentou um desempenho consistente em dados fora da amostra, sugerindo que estÃ¡ bem ajustado para o problema.


## Estrutura do Projeto

O projeto segue a estrutura proposta pelo TDSP:

```
ğŸ“ kobe_shot_prediction_tdsp/
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ preparacao_dados.py
â”‚   â”œâ”€â”€ treinamento.py
â”‚   â”œâ”€â”€ aplicacao.py
â”‚   â”œâ”€â”€ pipeline.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ dataset_kobe_dev.parquet
â”‚   â”‚   â””â”€â”€ dataset_kobe_prod.parquet
â”‚   â”œâ”€â”€ processed/
â”‚       â”œâ”€â”€ data_filtered.parquet
â”‚       â”œâ”€â”€ base_train.parquet
â”‚       â””â”€â”€ base_test.parquet
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ diagramas/
â”‚   â”œâ”€â”€ relatorios/
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ dashboards/
â”‚       â””â”€â”€ streamlit_app.py
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ environment.yml
```

---

## 2. Diagrama do Pipeline

O pipeline de desenvolvimento detalhado segue o seguinte fluxo:

1. **AquisiÃ§Ã£o de Dados**
   - Coleta dos arquivos e armazenamento na pasta `data/raw`.

2. **PrÃ©-processamento**
   - RemoÃ§Ã£o de nulos, seleÃ§Ã£o de colunas relevantes e salvamento em `data/processed`.

3. **SeparaÃ§Ã£o Treino/Teste**
   - DivisÃ£o estratificada 80/20 dos dados e armazenamento em `base_train.parquet` e `base_test.parquet`.

4. **Treinamento**
   - AplicaÃ§Ã£o de modelos de RegressÃ£o LogÃ­stica e Ãrvore de DecisÃ£o utilizando PyCaret e MLFlow.

5. **AvaliaÃ§Ã£o**
   - MÃ©tricas calculadas: Log-Loss, F1-score, entre outras.
   - SeleÃ§Ã£o do melhor modelo baseado nas mÃ©tricas calculadas.

6. **Deploy/OperacionalizaÃ§Ã£o**
   - Deploy do modelo utilizando MLFlow, API Flask ou Streamlit.

7. **Monitoramento**
   - Monitoramento contÃ­nuo das mÃ©tricas de desempenho em produÃ§Ã£o.

8. **AtualizaÃ§Ã£o do Modelo**
   - ReavaliaÃ§Ã£o e ajuste do modelo com novas coletas de dados.

### Diagrama Visual do Pipeline

![Diagrama do Pipeline](./docs/diagramas/questao_2_fluxograma.png)

---

## 3. FunÃ§Ãµes das Ferramentas

### ğŸ”¨ PyCaret
- Facilita o treinamento e a comparaÃ§Ã£o de modelos atravÃ©s de funÃ§Ãµes simplificadas.
- Permite testar mÃºltiplos algoritmos de classificaÃ§Ã£o e regressÃ£o.

### ğŸ”¨ Scikit-Learn
- Fornece algoritmos de machine learning essenciais para o projeto.
- Ã‰ utilizado em conjunto com o PyCaret para o treinamento dos modelos.

### ğŸ”¨ MLFlow
- Usado para rastrear experimentos e registrar mÃ©tricas.
- Facilita o deploy do modelo final.
- Permite monitorar o desempenho do modelo.

### ğŸ”¨ Streamlit
- Permite a criaÃ§Ã£o de dashboards interativos para visualizaÃ§Ã£o dos resultados.
- Facilita o monitoramento do desempenho do modelo.

---

## 4. Artefatos Criados

- `data_filtered.parquet`: Conjunto de dados limpo e filtrado.
- `base_train.parquet`: Dados de treino (80%).
- `base_test.parquet`: Dados de teste (20%).
- `final_model.pkl`: Modelo treinado e registrado no MLFlow.
- **Dashboard Streamlit**: VisualizaÃ§Ã£o dos resultados.

---

## 5. Pipeline de Processamento de Dados

A pipeline de processamento de dados inclui as seguintes etapas:
- Carregamento e limpeza dos dados.
- SeleÃ§Ã£o das colunas especificadas (`lat`, `lon`, `minutes_remaining`, `period`, `playoffs`, `shot_distance`, `shot_made_flag`).
- RemoÃ§Ã£o de linhas com valores ausentes.
- SeparaÃ§Ã£o dos dados em treino e teste (80% e 20%).
- Registro de mÃ©tricas no MLFlow.

---

## 6. Pipeline de Treinamento

O treinamento dos modelos Ã© realizado utilizando PyCaret, com duas abordagens principais:
- RegressÃ£o LogÃ­stica.
- Ãrvore de DecisÃ£o.

Os modelos sÃ£o avaliados utilizando mÃ©tricas de `Log Loss` e `F1_Score` e o melhor Ã© escolhido com base nessas mÃ©tricas.

---

## 7. Pipeline de AplicaÃ§Ã£o

A aplicaÃ§Ã£o do modelo Ã© feita atravÃ©s do script `aplicacao.py`, que:
- Carrega o modelo final registrado no MLFlow.
- Realiza previsÃµes na base de produÃ§Ã£o (`dataset_kobe_prod.parquet`).
- Registra os resultados e mÃ©tricas no MLFlow.

---

## 8. Dashboard Streamlit

Um dashboard interativo foi implementado usando Streamlit para monitorar o desempenho do modelo.

```bash
streamlit run outputs/dashboards/streamlit_app.py
```

---

## 9. RepositÃ³rio Git

O projeto estÃ¡ disponÃ­vel no repositÃ³rio GitHub: [Link do RepositÃ³rio](#)

---

## 10. ConclusÃ£o

O projeto foi desenvolvido com sucesso utilizando as ferramentas indicadas (PyCaret, Scikit-Learn, MLFlow e Streamlit). O pipeline completo foi implementado e o modelo final foi registrado e monitorado adequadamente.

---
