# Aluno: Marcelo Barros de Azevedo Vieira
## Disciplina: Engenharia de Machine Learning


# Kobe Bryant Shot Prediction - Framework TDSP

## Projeto de Engenharia de Machine Learning - Previs√£o de Acertos do Kobe Bryant

### Objetivo

Desenvolver um preditor de arremessos de Kobe Bryant usando duas abordagens: Regress√£o e Classifica√ß√£o. O projeto deve prever se Kobe Bryant acertou ou errou um arremesso, utilizando o Framework TDSP (Team Data Science Process).

---

## Como executar o projeto

### Criar ambiente Conda e instalar depend√™ncias:
Com YAML 
```bash
conda env create -f environment.yml
```

### Executar o pipeline completo do plrojeto:
```bash
python code/pipeline.py
```

### Exibir o dashboard:
```bash
streamlit run outuputs/dashboards/streamlit_app.py
```

### Abrir o MLflow:
```bash
mlflow ui
```
Acessar: [http://localhost:5000](http://localhost:5000)


## Principais tecnologias utilizadas no projeto 
- Python 3.10
- Pycaret 3.0.0
- Seaborn 0.13.2
- Pandas 2.2.3
- Scikit-Learn 1.5.1
- MLflow 2.21.2
- Streamlit 1.43.2
- NumPy 2.1.3
- Matplotlib 3.9.2

## M√©tricas Finais (Produ√ß√£o)

| **Modelo**          |**Log Loss**|**F1 Score**|
|---------------------|------------|------------|
| Regress√£o Log√≠stica | 0.45       | 0.65       |
| √Årvore de Decis√£o   | 0.38       | 0.72       |

O modelo de **√Årvore de Decis√£o** foi selecionado para produ√ß√£o por apresentar melhor desempenho geral em m√©tricas cr√≠ticas como `F1-Score` e `Log Loss` em compara√ß√£o √† Regress√£o Log√≠stica. Al√©m disso, a **√Årvore de Decis√£o** oferece maior interpretabilidade e melhor desempenho na base de produ√ß√£o.  

Embora o `Log Loss` n√£o seja perfeito, o modelo apresentou um desempenho consistente em dados fora da amostra, sugerindo que est√° bem ajustado para o problema.


## Estrutura do Projeto

O projeto segue a estrutura proposta pelo TDSP:

```
üìÅ kobe_shot_prediction_tdsp/
‚îú‚îÄ‚îÄ code/
‚îÇ   ‚îú‚îÄ‚îÄ preparacao_dados.py
‚îÇ   ‚îú‚îÄ‚îÄ treinamento.py
‚îÇ   ‚îú‚îÄ‚îÄ aplicacao.py
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dataset_kobe_dev.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dataset_kobe_prod.parquet
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ       ‚îú‚îÄ‚îÄ data_filtered.parquet
‚îÇ       ‚îú‚îÄ‚îÄ base_train.parquet
‚îÇ       ‚îî‚îÄ‚îÄ base_test.parquet
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ diagramas/
‚îÇ   ‚îú‚îÄ‚îÄ relatorios/
‚îú‚îÄ‚îÄ outputs/
‚îÇ   ‚îî‚îÄ‚îÄ dashboards/
‚îÇ       ‚îî‚îÄ‚îÄ streamlit_app.py
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ environment.yml
```

---

# **Respostas**

### Quest√£o 1) A solu√ß√£o criada nesse projeto deve ser disponibilizada em reposit√≥rio git e disponibilizada em servidor de reposit√≥rios (Github (recomendado), Bitbucket ou Gitlab). O projeto deve obedecer o Framework TDSP da Microsoft (estrutura de arquivos, arquivo requirements.txt e arquivo README - com as respostas pedidas nesse projeto, al√©m de outras informa√ß√µes pertinentes). Todos os artefatos produzidos dever√£o conter informa√ß√µes referentes a esse projeto (n√£o ser√£o aceitos documentos vazios ou fora de contexto). Escreva o link para seu reposit√≥rio.
### Resposta: https://github.com/marcelobazevedo/kobe_shot_prediction_tdsp
---
### Quest√£o 2) Iremos desenvolver um preditor de arremessos usando duas abordagens (regress√£o e classifica√ß√£o) para prever se o "Black Mamba" (apelido de Kobe) acertou ou errou a cesta. Baixe os dados de desenvolvimento e produ√ß√£o aqui (datasets: dataset_kobe_dev.parquet e dataset_kobe_prod.parquet). Salve-os numa pasta /data/raw na raiz do seu reposit√≥rio. Para come√ßar o desenvolvimento, desenhe um diagrama que demonstra todas as etapas necess√°rias para esse projeto, desde a aquisi√ß√£o de dados, passando pela cria√ß√£o dos modelos, indo at√© a opera√ß√£o do modelo.
### Resposta: 

1. **Aquisi√ß√£o de Dados**
   - Coleta dos arquivos e armazenamento na pasta `data/raw`.

2. **Pr√©-processamento**
   - Remo√ß√£o de nulos, sele√ß√£o de colunas relevantes e salvamento em `data/processed`.

3. **Separa√ß√£o Treino/Teste**
   - Divis√£o estratificada 80/20 dos dados e armazenamento em `base_train.parquet` e `base_test.parquet`.

4. **Treinamento**
   - Aplica√ß√£o de modelos de Regress√£o Log√≠stica e √Årvore de Decis√£o utilizando PyCaret e MLFlow.

5. **Avalia√ß√£o**
   - M√©tricas calculadas: Log-Loss, F1-score, entre outras.
   - Sele√ß√£o do melhor modelo baseado nas m√©tricas calculadas.

6. **Deploy/Operacionaliza√ß√£o**
   - Deploy do modelo utilizando MLFlow, API Flask ou Streamlit.

7. **Monitoramento**
   - Monitoramento cont√≠nuo das m√©tricas de desempenho em produ√ß√£o.

8. **Atualiza√ß√£o do Modelo**
   - Reavalia√ß√£o e ajuste do modelo com novas coletas de dados.

### Diagrama das etapas necess√°ria para o projeto

![Diagrama do Pipeline](./diagramas/questao_2_fluxograma.png)

---
### Quest√£o 3) Como as ferramentas Streamlit, MLFlow, PyCaret e Scikit-Learn auxiliam na constru√ß√£o dos pipelines descritos anteriormente? A resposta deve abranger os seguintes aspectos:

#### - Rastreamento de experimentos;
#### - Fun√ß√µes de treinamento;
#### - Monitoramento da sa√∫de do modelo;
#### - Atualiza√ß√£o de modelo;
#### - Provisionamento (Deployment).
### Resposta: 

####  PyCaret
- Oferece integra√ß√£o nativa com o MLFlow, automatizando o processo de logging.
- Permite que as m√©tricas de desempenho como F1-Score e Log Loss sejam registradas automaticamente durante o treinamento.
- Simplifica o gerenciamento de experimentos ao integrar o rastreamento de forma direta durante a cria√ß√£o dos modelos.

####  Scikit-Learn
- Base s√≥lida para implementa√ß√£o de algoritmos de aprendizado supervisionado, como Regress√£o Log√≠stica e √Årvore de Decis√£o.
- Permite c√°lculos manuais de m√©tricas importantes, garantindo flexibilidade na avalia√ß√£o dos modelos.
- Facilita a exporta√ß√£o e importa√ß√£o de modelos utilizando o m√≥dulo joblib

####  MLFlow
- Facilita o gerenciamento de experimentos ao registrar m√©tricas, par√¢metros e artefatos de cada modelo treinado.
- Permite rastrear o hist√≥rico de execu√ß√µes, comparar resultados e acessar modelos anteriores para an√°lise ou reutiliza√ß√£o.
- PNo projeto, o MLFlow √© usado para garantir que todas as execu√ß√µes do pipeline de treinamento e aplica√ß√£o sejam devidamente registradas.

####  Streamlit
- Fornece uma interface gr√°fica para visualiza√ß√£o e an√°lise dos resultados em tempo real.
- Permite criar dashboards din√¢micos que exibem m√©tricas relevantes de desempenho e resultados de predi√ß√µes.
- Facilita a identifica√ß√£o de problemas atrav√©s da an√°lise visual dos resultados

---

### Quest√£o 4) Com base no diagrama realizado na quest√£o 2, aponte os artefatos que ser√£o criados ao longo de um projeto. Para cada artefato, a descri√ß√£o detalhada de sua composi√ß√£o.
### Resposta: 

O projeto de Machine Learning desenvolvido neste trabalho cria diversos artefatos em diferentes etapas do pipeline, conforme descrito no diagrama. Cada artefato possui uma composi√ß√£o espec√≠fica e um papel fundamental no sucesso do projeto.

### **1. Dados Brutos (`/data/raw`)**
- **`dataset_kobe_dev.parquet`**: Dados originais destinados ao desenvolvimento e treinamento do modelo.
- **`dataset_kobe_prod.parquet`**: Dados que representam o ambiente de produ√ß√£o para avalia√ß√£o do modelo treinado.

### **2. Dados Processados (`/data/processed`)**
- **`data_filtered.parquet`**: Dados filtrados e pr√©-processados, considerando as colunas selecionadas e eliminando dados ausentes.
- **`base_train.parquet`** e **`base_test.parquet`**: Dados de treino e teste gerados a partir da divis√£o estratificada.
- **`resultado_producao.parquet`**: Resultados das previs√µes realizadas na fase de aplica√ß√£o.

### **3. Modelos Treinados (`/data/processed`)**
- **`final_model.pkl`**: Arquivo contendo o modelo final treinado e salvo utilizando a biblioteca PyCaret.

### **4. Relat√≥rios e M√©tricas (`/outputs/mlruns`)**
- Diret√≥rios gerados pelo MLFlow contendo logs detalhados de cada experimento.
- Inclui m√©tricas como **Log Loss** e **F1-Score**, al√©m de par√¢metros dos modelos treinados e artefatos gerados.

### **5. Interface de Aplica√ß√£o (`/outputs/dashboards`)**
- **`streamlit_app.py`**: Dashboard interativo desenvolvido com Streamlit para visualiza√ß√£o de m√©tricas e previs√£o de novos arremessos.

### **6. Relat√≥rio Final (`README.md`)**
- Documenta√ß√£o completa do projeto, contendo descri√ß√£o do problema, estrutura do pipeline, artefatos gerados e justificativas das escolhas feitas durante o desenvolvimento.

### **7. Arquivo de Ambiente (`environment.yml`)**
- Arquivo que especifica todas as depend√™ncias necess√°rias para execu√ß√£o do projeto.
- Inclui bibliotecas como **PyCaret**, **MLFlow**, **Streamlit** e **Scikit-Learn**.

---


### Quest√£o 5) Implemente o pipeline de processamento de dados com o mlflow, rodada (run) com o nome `"PreparacaoDados"`:

- **a.** Os dados devem estar localizados em:
  - `/data/raw/dataset_kobe_dev.parquet` 
  - `/data/raw/dataset_kobe_prod.parquet` 

- **b.** Observe que h√° dados faltantes na base de dados! As linhas que possuem dados faltantes devem ser desconsideradas. Para esse exerc√≠cio ser√£o apenas consideradas as colunas: 
  - `lat`
  - `lon`
  - `minutes_remaining`
  - `period`
  - `playoffs`
  - `shot_distance`
  - `shot_made_flag` (vari√°vel alvo onde: `0` = erro, `1` = acerto)
  
  O dataset resultante ser√° armazenado na pasta:  
  `/data/processed/data_filtered.parquet`  

  Ainda sobre essa sele√ß√£o, qual a dimens√£o resultante do dataset?

- **c.** Separe os dados em treino (80%) e teste (20%) usando uma escolha aleat√≥ria e estratificada. 

  - Armazene os datasets resultantes em:  
    - `/data/processed/base_train.parquet`
    - `/data/processed/base_test.parquet`
    
  Explique como a escolha de treino e teste afetam o resultado do modelo final. Quais estrat√©gias ajudam a minimizar os efeitos de vi√©s de dados?

- **d.** Registre os par√¢metros (% teste) e m√©tricas (tamanho de cada base) no MLFlow.


### Resposta: 

A pipeline de processamento de dados inclui as seguintes etapas:
- Carregamento e limpeza dos dados.
- Sele√ß√£o das colunas especificadas (`lat`, `lon`, `minutes_remaining`, `period`, `playoffs`, `shot_distance`, `shot_made_flag`).
- Remo√ß√£o de linhas com valores ausentes.
- Separa√ß√£o dos dados em treino e teste (80% e 20%).
- Registro de m√©tricas no MLFlow.


### Descri√ß√£o Geral
O pipeline de processamento de dados √© respons√°vel por preparar o dataset para treinamento e avalia√ß√£o do modelo. Este processo √© implementado no arquivo `preparacao_dados.py` e √© registrado como um experimento no **MLFlow**.




#### 1. Carregamento dos Dados
- Os dados s√£o carregados a partir de arquivos `.parquet` localizados no diret√≥rio `/data/raw`.

```python
dev_path = os.path.join(raw_dir, "dataset_kobe_dev.parquet")
df_dev = pd.read_parquet(dev_path)
```
### 2. Sele√ß√£o de Colunas Relevantes

    Apenas as colunas necess√°rias para o treino e avalia√ß√£o do modelo s√£o selecionadas.

    Colunas selecionadas:

        lat

        lon

        minutes_remaining

        period

        playoffs

        shot_distance

        shot_made_flag (Alvo)

```python
colunas = ['lat', 'lon', 'minutes_remaining', 'period', 'playoffs', 'shot_distance', 'shot_made_flag']
df_dev = df_dev[colunas]
```

### 3. Tratamento de Dados Faltantes

    Linhas que possuem valores faltantes s√£o desconsideradas do dataset.
```python
df_dev = df_dev.dropna()
```

### 4. Salvamento do Dataset Filtrado

    O dataset filtrado √© salvo no diret√≥rio /data/processed.
```python
filtered_path = os.path.join(processed_dir, "data_filtered.parquet")
df_dev.to_parquet(filtered_path, index=False)
```

### 5. Separa√ß√£o em Treino e Teste
   Os dados s√£o divididos em treino (80%) e teste (20%) utilizando amostragem estratificada para garantir a mesma propor√ß√£o da vari√°vel alvo shot_made_flag em ambos os conjuntos.
```python
X = df_dev.drop("shot_made_flag", axis=1)
y = df_dev["shot_made_flag"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
```

### 6. Salvamento dos Datasets de Treino e Teste

    Os datasets resultantes s√£o armazenados no diret√≥rio /data/processed.
```python
train_path = os.path.join(processed_dir, "base_train.parquet")
test_path = os.path.join(processed_dir, "base_test.parquet")
train_df.to_parquet(train_path, index=False)
test_df.to_parquet(test_path, index=False)
```

### 7. Registro de Par√¢metros e M√©tricas no MLFlow

    - Par√¢metros registrados:

        Tamanho do conjunto de teste (test_size)

        Estado aleat√≥rio para reprodutibilidade (random_state)

        Colunas utilizadas (colunas_utilizadas)

    - M√©tricas registradas:

        Tamanho do conjunto de treino (train_size)

        Tamanho do conjunto de teste (test_size)

```python
mlflow.log_param("test_size", 0.2)
mlflow.log_param("random_state", 123)
mlflow.log_param("colunas_utilizadas", colunas)
mlflow.log_metric("train_size", len(train_df))
mlflow.log_metric("test_size", len(test_df))
```

![M√©tricas s par√¢mtros MLFlow](./imagens/param_metric_mlflow.png)
---
### Quest√£o 6) Implementar o pipeline de treinamento do modelo com o MlFlow usando o nome "Treinamento" 
- **a.** Com os dados separados para treinamento, treine um modelo com regress√£o log√≠stica do sklearn usando a biblioteca pyCaret.
- **b.** Registre a fun√ß√£o custo "log loss" usando a base de teste
- **c.** Com os dados separados para treinamento, treine um modelo de √°rvore de decis√£o do sklearn usando a biblioteca pyCaret.
- **d.** Registre a fun√ß√£o custo "log loss" e F1_score para o modelo de √°rvore.
- **e.** Selecione um dos dois modelos para finaliza√ß√£o e justifique sua escolha.

### Resposta: 
## 6. Pipeline de Treinamento do Modelo com o MLFlow (`Treinamento`)

Implementar o pipeline de treinamento do modelo com o MLFlow usando o nome `"Treinamento"`.

### a. Treinamento do Modelo de Regress√£o Log√≠stica

- Com os dados separados para treinamento, um modelo de **Regress√£o Log√≠stica** √© treinado utilizando a biblioteca **PyCaret**.
- O PyCaret facilita o processo de configura√ß√£o, treinamento, compara√ß√£o de modelos e registro autom√°tico no MLFlow.
```python
# Setup do PyCaret
    clf1 = setup(
        data=train_df,
        target='shot_made_flag',
        session_id=123,
        verbose=False
    )

    # Treinamento - Regress√£o Log√≠stica
    log_model = create_model('lr')
    results_lr = pull()
```

### b. Registro da Fun√ß√£o Custo - `Log Loss` (Regress√£o Log√≠stica)

- A m√©trica **Log Loss** √© calculada utilizando a base de teste (`base_test.parquet`).
- O resultado √© registrado no MLFlow para posterior compara√ß√£o com outros modelos.
```python
predictions_lr = predict_model(log_model, data=test_df)

if 'prediction_score' in predictions_lr.columns:
    prob_lr = predictions_lr['prediction_score']
    pred_labels_lr = predictions_lr['prediction_label']
else:
    raise ValueError("A coluna 'prediction_score' n√£o foi encontrada.")

# Calcular m√©tricas
log_loss_lr = log_loss(y_test, prob_lr)
f1_score_lr = f1_score(y_test, pred_labels_lr)
    
mlflow.log_metric("f1_score_lr", f1_score_lr)
mlflow.log_metric("log_loss_lr", log_loss_lr)
```

### c. Treinamento do Modelo de √Årvore de Decis√£o

- Com os dados separados para treinamento, um modelo de **√Årvore de Decis√£o** √© treinado utilizando a biblioteca **PyCaret**.
- Assim como na Regress√£o Log√≠stica, o PyCaret √© utilizado para automatizar o processo de treinamento e registro de m√©tricas no MLFlow.
```python
# Treinamento - √Årvore de Decis√£o
tree_model = create_model('dt')
results_dt = pull()
```
### d. Registro das M√©tricas - `Log Loss` e `F1 Score` (√Årvore de Decis√£o)

- As m√©tricas **Log Loss** e **F1 Score** s√£o calculadas utilizando a base de teste (`base_test.parquet`).
- Ambas s√£o registradas no MLFlow, permitindo a compara√ß√£o direta entre os modelos treinados.
```python
# Realiza predi√ß√µes e coleta a probabilidade de acerto
predictions_dt = predict_model(tree_model, data=test_df)

if 'prediction_score' in predictions_dt.columns:
    prob_dt = predictions_dt['prediction_score']
    pred_labels_dt = predictions_dt['prediction_label']
else:
    raise ValueError("A coluna 'prediction_score' n√£o foi encontrada.")

# Calcular m√©tricas
log_loss_dt = log_loss(y_test, prob_dt)
f1_score_dt = f1_score(y_test, pred_labels_dt)
    
mlflow.log_metric("f1_score_dt", f1_score_dt)
mlflow.log_metric("log_loss_dt", log_loss_dt)

```

### e. Sele√ß√£o do Modelo Final

- O modelo selecionado para finaliza√ß√£o foi a **√Årvore de Decis√£o**, com base na compara√ß√£o das m√©tricas `Log Loss` e `F1 Score`.
- A **√Årvore de Decis√£o** foi escolhida devido ao seu melhor desempenho em rela√ß√£o ao `F1 Score`, o que indica melhor equil√≠brio entre precis√£o e revoca√ß√£o.
- Al√©m disso, a √°rvore de decis√£o oferece maior interpretabilidade, facilitando a an√°lise dos resultados.

```python
if f1_score_dt > f1_score_lr:
    best_model = tree_model
    model_name = "DecisionTree"
else:
    best_model = log_model
    model_name = "LogisticRegression"

mlflow.log_param("final_model", model_name)
mlflow.log_metric("best_model_f1_score", max(f1_score_dt, f1_score_lr))
mlflow.log_metric("best_model_log_loss", log_loss_dt if f1_score_dt > f1_score_lr else log_loss_lr)

```

> **Justificativa:** Embora o modelo de Regress√£o Log√≠stica apresente um desempenho satisfat√≥rio, a **√Årvore de Decis√£o** obteve um melhor `F1 Score`, o que √© relevante considerando a necessidade de precis√£o e revoca√ß√£o balanceadas no problema proposto.
---
### Quest√£o 7) Registre o modelo de classifica√ß√£o e o sirva atrav√©s do MLFlow (ou como uma API local, ou embarcando o modelo na aplica√ß√£o). Desenvolva um pipeline de aplica√ß√£o (aplicacao.py) para carregar a base de produ√ß√£o (/data/raw/dataset_kobe_prod.parquet) e aplicar o modelo. Nomeie a rodada (run) do mlflow como ‚ÄúPipelineAplicacao‚Äù e publique, tanto uma tabela com os resultados obtidos (artefato como .parquet), quanto log as m√©tricas do novo log loss e f1_score do modelo.
- **a.** O modelo √© aderente a essa nova base? O que mudou entre uma base e outra? Justifique.
- **b.** Descreva como podemos monitorar a sa√∫de do modelo no cen√°rio com e sem a disponibilidade da vari√°vel resposta para o modelo em opera√ß√£o.
- **c.** Descreva as estrat√©gias reativa e preditiva de retreinamento para o modelo em opera√ß√£o.

### Resposta: 

## 7. Registro e Servir do Modelo com o MLFlow (`PipelineAplicacao`)

Implementar o pipeline de aplica√ß√£o do modelo treinado, servir o modelo e registrar os resultados utilizando o **MLFlow** com o nome `"PipelineAplicacao"`.

---

### a. O modelo √© aderente a essa nova base? O que mudou entre uma base e outra? Justifique.

- **Ader√™ncia do Modelo:** Ap√≥s aplicar o modelo treinado na base de produ√ß√£o (`/data/raw/dataset_kobe_prod.parquet`), as m√©tricas registradas (`Log Loss` e `F1 Score`) devem ser comparadas com aquelas obtidas durante o treinamento e teste iniciais.
- **Mudan√ßas entre as bases:**
  - A base de produ√ß√£o pode apresentar distribui√ß√µes diferentes nas vari√°veis de entrada (`lat`, `lon`, `minutes_remaining`, `period`, `playoffs`, `shot_distance`) em rela√ß√£o aos dados usados para o treinamento e teste (`dataset_kobe_dev.parquet`).
  - Caso as m√©tricas calculadas na base de produ√ß√£o sejam significativamente piores do que aquelas obtidas durante o treinamento, √© poss√≠vel que o modelo n√£o seja adequado para a nova base de produ√ß√£o.
- **Justificativa:** 
  - O modelo √© considerado aderente se suas m√©tricas mantiverem um desempenho consistente quando aplicado √† nova base.
  - Desvios significativos indicam que o modelo deve ser reavaliado ou retreinado para melhor se adequar √†s caracter√≠sticas da base de produ√ß√£o.

---

### b. Descreva como podemos monitorar a sa√∫de do modelo no cen√°rio com e sem a disponibilidade da vari√°vel resposta para o modelo em opera√ß√£o.

1. **Cen√°rio com a disponibilidade da vari√°vel resposta (`shot_made_flag`):**
   - Quando a vari√°vel resposta (`shot_made_flag`) est√° dispon√≠vel, √© poss√≠vel monitorar o desempenho do modelo de maneira cont√≠nua.
   - M√©tricas como `Log Loss`, `F1 Score`, `Accuracy`, entre outras, podem ser calculadas e comparadas com os valores obtidos durante o treinamento inicial.
   - Essas m√©tricas devem ser registradas no MLFlow regularmente para facilitar o monitoramento e an√°lise da sa√∫de do modelo.

2. **Cen√°rio sem a disponibilidade da vari√°vel resposta (Produ√ß√£o sem labels):**
   - Sem a vari√°vel resposta (`shot_made_flag`), o monitoramento deve ser feito de forma indireta.
   - Poss√≠veis abordagens incluem:
     - **Monitoramento de Distribui√ß√£o:** Comparar a distribui√ß√£o das previs√µes atuais com as distribui√ß√µes obtidas durante o treinamento.
     - **Monitoramento da Confian√ßa:** Acompanhar os `Confidence Scores` das previs√µes para identificar padr√µes an√¥malos.
     - **Detec√ß√£o de Drift:** Detectar mudan√ßas nas distribui√ß√µes dos dados de entrada que possam indicar degrada√ß√£o do desempenho do modelo.
   - Este monitoramento pode ser registrado no MLFlow por meio de m√©tricas customizadas ou artefatos gerados periodicamente.

---

### c. Descreva as estrat√©gias reativa e preditiva de retreinamento para o modelo em opera√ß√£o.

1. **Estrat√©gia Reativa:**
   - O retreinamento √© realizado **ap√≥s** a detec√ß√£o de uma queda significativa no desempenho do modelo.
   - A degrada√ß√£o √© identificada por meio de monitoramento cont√≠nuo das m√©tricas (`Log Loss`, `F1 Score`) registradas no MLFlow.
   - Quando uma m√©trica cai abaixo de um limite pr√©-definido, o retreinamento √© acionado.
   - Exemplo: Se o `F1 Score` cair abaixo de 0.50, o modelo √© retreinado usando uma nova amostra de dados atualizados.

2. **Estrat√©gia Preditiva:**
   - O retreinamento √© realizado de maneira **preventiva**, antes que o desempenho do modelo se deteriore.
   - T√©cnicas de previs√£o s√£o aplicadas para identificar quando o modelo precisa ser atualizado.
   - Pode envolver o uso de algoritmos de detec√ß√£o de drift ou monitoramento cont√≠nuo das distribui√ß√µes dos dados de entrada.
   - Este m√©todo √© √∫til para evitar quedas bruscas de desempenho, mantendo o modelo sempre atualizado.

---

### Quest√£o 8) Implemente um dashboard de monitoramento da opera√ß√£o usando Streamlit.

Um dashboard interativo foi implementado usando Streamlit para monitorar o desempenho do modelo.

```bash
streamlit run outputs/dashboards/streamlit_app.py
```
![Dashboard Streamlit](./imagens/dashboard_streamlit.png)
---
![Dashboard MLFlow](./imagens/mlflow_1.png)
---
![Dashboard MLFlow](./imagens/mlflow_2.png)
---
![Dashboard MLFlow](./imagens/mlflow_3.png)
---
![Dashboard MLFlow](./imagens/mlflow_4.png)
---
![Dashboard MLFlow](./imagens/mlflow_5.png)
---
![Dashboard MLFlow](./imagens/mlflow_6.png)
---
![Dashboard MLFlow](./imagens/mlflow_7.png)
---
![Dashboard MLFlow](./imagens/mlflow_8.png)
---
![Dashboard MLFlow](./imagens/mlflow_9.png)
---
## R√∫bricas

### 1. Desenvolver um sistema de coleta de dados usando APIs p√∫blicas
#### 1.1 O aluno categorizou corretamente os dados?
##### - Respondido na quest√£o 5.
#### 1.2 O aluno integrou a leitura dos dados corretamente √† sua solu√ß√£o?
##### - Respondido nas quest√µes 5, 6 e 7. Os dados s√£o integrados por `pipeline.py` que executa `preparacao_dado.py`, `treinamento.py` e `aplicacao.py` 
#### 1.3 O aluno aplicou o modelo em produ√ß√£o (servindo como API ou como solu√ß√£o embarcada)?
   ##### - Sim. A arquivo `aplicacao.py` realiza esta opera√ß√£o.
#### 1.4 O aluno indicou se o modelo √© aderente a nova base de dados?
   #### - Sim. A resposta esta contida na quest√£o 7.a

### 2. Criar uma solu√ß√£o de streaming de dados usando pipelines
#### 2.1 O aluno criou um reposit√≥rio git com a estrutura de projeto baseado no Framework TDSP da Microsoft?
##### - Sim. Foi criado uma estrutura com as pastas code, data, docs, notebooks, requirements.txt, environment.yaml e README.md
#### 2.2 O aluno criou um diagrama que mostra todas as etapas necess√°rias para a cria√ß√£o de modelos?
##### - Sim. Respondido na quest√£o 2.
#### 2.3 O aluno treinou um modelo de regress√£o usando PyCaret e MLflow?
##### - Sim. No arquivo `treinamento.py` foi realizado o treinamento que foi respondiso na quest√£o 6.a.
#### 2.4 O aluno calculou o Log Loss para o modelo de regress√£o e registrou no mlflow?
##### - Sim. O Log Loss foi calculado e restridado conforme visto na quest√£o 6.b
#### 2.5 O aluno treinou um modelo de √°rvore de decisao usando PyCaret e MLflow?
##### - Sim. Foi respondido na quest√£o 6.c
#### 2.6 O aluno calculou o Log Loss e F1 Score para o modelo de √°rvore de decis√£o e registrou no mlflow?
##### - Sim. Os dois foram calculados e registrados no MLFlow, conforme quest√£o 6.d

### 3. Preparar um modelo previamente treinado para uma solu√ß√£o de streaming de dados
#### 3.1 O aluno indicou o objetivo e descreveu detalhadamente cada artefato criado no projeto?
##### -  Sim. Respondido na quest√£o 4.
#### 3.2 O aluno cobriu todos os artefatos do diagrama proposto?
##### - Sim. Todos os artefatos foram implementados conforme quest√£o 4.
#### 3.3 O aluno usou o MLFlow para registrar a rodada "Prepara√ß√£o de Dados" com as m√©tricas e argumentos relevantes?
##### - Sim. Foi usado `mlflow.set_experiment("PreparacaoDados")` e `mlflow.start_run(run_name="PreparacaoDados"):`
#### 3.4 O aluno removeu os dados faltantes da base?
##### - Sim. Respondido na quest√£o 5.
#### 3.5 O aluno selecionou as colunas indicadas para criar o modelo?
##### - Sim. Apenas as colunas do n√∫mero 5 do enunciado foram mantidas.
#### 3.6 O aluno indicou quais as dimens√µes para a base preprocessada?
##### - Sim
#### 3.7 O aluno criou arquivos para cada fase do processamento e os armazenou nas pastas indicadas?
##### - Sim. Respondido na quest√£o 5.
#### 3.8 O aluno separou em duas bases, uma para treino e outra para teste?
##### - Sim. Foi respondido na quest√£o 5
#### 3.9 O aluno criou um pipeline chamado "Treinamento" no MlFlow?
##### - Sim. `mlflow.set_experiment("Treinamento")`

### 4. Estabelecer um m√©todo de como atualizar o modelo empregado em produ√ß√£o
#### 4.1 O aluno identificou a diferen√ßa entre a base de desenvolvimento e produ√ß√£o?
##### Sim. A identifica√ß√£o ocorre durante a aplica√ß√£o do modelo em produ√ß√£o, onde o arquivo dataset_kobe_prod.parquet √© utilizado e comparado com o modelo treinado na base de desenvolvimento (`dataset_kobe_dev.parquet`).
#### 4.2 O aluno descreveu como monitorar a sa√∫de do modelo no cen√°rio com e sem a disponibilidade da vari√°vel alvo?
##### Sim, o aluno descreveu como monitorar a sa√∫de do modelo considerando dois cen√°rios em que se conhece a vari√°vel resposta dispon√≠vel e sem vari√°vel resposta dispon√≠vel.
#### 4.3 O aluno implementou um dashboard de monitoramento da opera√ß√£o usando Streamlit?
##### - Sim. O dashboard foi implementado utilizando o Streamlit e pode ser acessado atrav√©s do arquivo streamlit_app.py.
#### 4.4 O aluno descreveu as estrat√©gias reativa e preditiva de retreinamento para o modelo em opera√ß√£o?
##### Sim. Foi respondido na quest√£o 7.